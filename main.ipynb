{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5ForConditionalGeneration\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5Tokenizer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaTokenizer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.utils'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoModelForSeq2SeqLM \n",
    "import torch\n",
    "\n",
    "## çzetlenecek kod örneği\n",
    "code_review = \"\"\"\n",
    "\n",
    "function calculateSquares(numbers) {\n",
    "    const result = {};\n",
    "\n",
    "    numbers.forEach(number => {\n",
    "        if (typeof number === 'number') {\n",
    "            result[number] = number * number;\n",
    "        } else {\n",
    "            console.warn(`${number} is not a number`);\n",
    "        }\n",
    "    });\n",
    "\n",
    "    return result;\n",
    "}\n",
    "\n",
    "console.log\n",
    "\"\"\"\n",
    "\n",
    "# Yerine getirilecek text input\n",
    "code_generate = \"write javascript function to calculate the sum of given two numbers\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobertaTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./weights_all_models/Salesforce_codet5-base-multi-sum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./weights_all_models/api/saved-pretrained-kde-cpp-tm\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RobertaTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Hazır finetune edilmiş bir modelin kullanımı.\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"./weights_all_models/Salesforce_codet5-base-multi-sum\")\n",
    "model = T5ForConditionalGeneration.from_pretrained('./weights_all_models/api/saved-pretrained-kde-cpp-tm').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RobertaTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m konum \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_all_models/Salesforce_codet5-base-multi-sum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Model ve tokenizer'ı yükle\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(konum)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(konum)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RobertaTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Salesforce/codet5-base-multi-sum modelinin kullanımı\n",
    "konum = \"weights_all_models/Salesforce_codet5-base-multi-sum\"\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(konum)\n",
    "model = T5ForConditionalGeneration.from_pretrained(konum).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salesforce/codet5p-770m-py modelinin kullanımı\n",
    "konum = \"weights_all_models/Salesforce_codet5p-770m-py\"\n",
    "\n",
    "# Model ve tokenizer'ı yükle\n",
    "tokenizer = RobertaTokenizer.from_pretrained(konum)\n",
    "model = T5ForConditionalGeneration.from_pretrained(konum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# javascript kodu özetlemek icin özel olarak eğitilmiş modelin kullanımı\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-large\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-base-codexglue-sum-javascript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      2\u001b[0m     input_ids, \n\u001b[0;32m      3\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, \n\u001b[0;32m      4\u001b[0m     repetition_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.2\u001b[39m,  \u001b[38;5;66;03m# Tekrar cezalandırması\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     no_repeat_ngram_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m   \u001b[38;5;66;03m# 3-gram tekrarlarını engelle\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m gpu_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time  \u001b[38;5;66;03m# Zaman ölçümü biter\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()  # Zaman ölçümü başlar\n",
    "\n",
    "input_ids = tokenizer(code, return_tensors='pt').input_ids.cuda()\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids, \n",
    "    max_new_tokens=300, \n",
    "    repetition_penalty=1.2,  # Tekrar cezalandırması\n",
    "    no_repeat_ngram_size=3   # 3-gram tekrarlarını engelle\n",
    ")\n",
    "\n",
    "gpu_time = time.time() - start_time  # Zaman ölçümü biter\n",
    "\n",
    "print(\"Result:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "print(f\"GPU execution time: {gpu_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
